# -*- coding: utf-8 -*-
"""Untitled36.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gmVhMM9dB9iTcVt_f_TWQz9KtJN_0_3g
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Reproducibility settings
import os, random
SEED = 42

os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

print("Devices:", tf.config.list_physical_devices())


(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

print("Training data shape:", x_train.shape)
print("Test data shape:", x_test.shape)
plt.figure(figsize=(6, 6))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(x_train[i], cmap='gray')
    plt.title(f"Label: {y_train[i]}")
    plt.axis('off')
plt.tight_layout()
plt.show()
x_train_flat = x_train.reshape((x_train.shape[0], 28 * 28))
x_test_flat = x_test.reshape((x_test.shape[0], 28 * 28))

x_train_flat = x_train_flat.astype('float32') / 255.0
x_test_flat = x_test_flat.astype('float32') / 255.0

y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)

print("Flattened training shape:", x_train_flat.shape)
print("One-hot label shape:", y_train_cat.shape)
# Build model with regularization + dropout
def build_model(activation_fn):
    model = Sequential([
        Dense(256, activation=activation_fn, input_shape=(784,), kernel_regularizer=l2(0.001)),
        Dropout(0.2),

        Dense(256, activation=activation_fn, kernel_regularizer=l2(0.001)),
        Dropout(0.2),

        Dense(128, activation=activation_fn, kernel_regularizer=l2(0.001)),
        Dropout(0.2),

        Dense(128, activation=activation_fn, kernel_regularizer=l2(0.001)),
        Dropout(0.2),

        Dense(64, activation=activation_fn, kernel_regularizer=l2(0.001)),
        Dropout(0.2),

        Dense(64, activation=activation_fn, kernel_regularizer=l2(0.001)),
        Dropout(0.2),

        Dense(10, activation='softmax')
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Early stopping callback
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)
def build_model(activation_fn):
    model = Sequential([
        Dense(256, activation=activation_fn, input_shape=(784,)),
        Dense(256, activation=activation_fn),
        Dense(128, activation=activation_fn),
        Dense(128, activation=activation_fn),
        Dense(64, activation=activation_fn),
        Dense(64, activation=activation_fn),
        Dense(10, activation='softmax')
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

sigmoid_model = build_model('sigmoid')
sigmoid_model.summary()

history_sigmoid = sigmoid_model.fit(
    x_train_flat, y_train_cat,
    epochs=10,
    batch_size=128,
    validation_data=(x_test_flat, y_test_cat),
    callbacks=[early_stop],
    verbose=1
)
tanh_model = build_model('tanh')
tanh_model.summary()

history_tanh = tanh_model.fit(
    x_train_flat, y_train_cat,
    epochs=10,
    batch_size=128,
    validation_data=(x_test_flat, y_test_cat),
    callbacks=[early_stop],
    verbose=1
)

model_summary_table = pd.DataFrame([
    {
        "Model": "Sigmoid",
        "Total Parameters": sigmoid_model.count_params(),
        "Hidden Layers": 6,
        "Output Units": 10,
        "Activation": "Sigmoid"
    },
    {
        "Model": "Tanh",
        "Total Parameters": tanh_model.count_params(),
        "Hidden Layers": 6,
        "Output Units": 10,
        "Activation": "Tanh"
    }
])

print("\n===== Model Architecture Summary =====")
print(model_summary_table.to_string(index=False))

plt.figure(figsize=(8, 5))
plt.plot(history_sigmoid.history['accuracy'], label='Sigmoid - Train')
plt.plot(history_sigmoid.history['val_accuracy'], label='Sigmoid - Val')
plt.plot(history_tanh.history['accuracy'], label='Tanh - Train')
plt.plot(history_tanh.history['val_accuracy'], label='Tanh - Val')
plt.title('Training and Validation Accuracy: Sigmoid vs Tanh')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

sigmoid_loss, sigmoid_acc = sigmoid_model.evaluate(x_test_flat, y_test_cat, verbose=0)
tanh_loss, tanh_acc = tanh_model.evaluate(x_test_flat, y_test_cat, verbose=0)

def final_metrics_row(model_name, history, test_loss, test_acc):
    return {
        "Model": model_name,
        "Train Loss": history.history['loss'][-1],
        "Val Loss": history.history['val_loss'][-1],
        "Train Accuracy": history.history['accuracy'][-1],
        "Val Accuracy": history.history['val_accuracy'][-1],
        "Test Loss": test_loss,
        "Test Accuracy": test_acc
    }

summary_rows = [
    final_metrics_row("Sigmoid", history_sigmoid, sigmoid_loss, sigmoid_acc),
    final_metrics_row("Tanh", history_tanh, tanh_loss, tanh_acc),
]

summary_table = pd.DataFrame(summary_rows)

print("\n===== Final Model Comparison Summary =====")
print(summary_table.to_string(index=False))

def show_misclassified_examples(model, model_name, x_test_flat, x_test_images, y_true, n=16):
    """
    Displays a grid of misclassified images with:
      - True label
      - Predicted label
      - Confidence of the predicted class
    """
    # Predict
    probs = model.predict(x_test_flat, verbose=0)
    y_pred = np.argmax(probs, axis=1)

    # Find wrong predictions
    wrong_idx = np.where(y_pred != y_true)[0]

    if len(wrong_idx) == 0:
        print(f"\nNo misclassifications found for {model_name}.")
        return

    # Select first n (or random n)
    # chosen = wrong_idx[:n]  # first n
    chosen = np.random.choice(wrong_idx, size=min(n, len(wrong_idx)), replace=False)  # random n

    print(f"\n===== Misclassified Examples: {model_name} =====")
    print(f"Total misclassified: {len(wrong_idx)} / {len(y_true)}")

    cols = int(np.sqrt(n))
    rows = int(np.ceil(n / cols))

    plt.figure(figsize=(2.2 * cols, 2.2 * rows))

    for i, idx in enumerate(chosen):
        true_label = y_true[idx]
        pred_label = y_pred[idx]
        confidence = probs[idx, pred_label]

        plt.subplot(rows, cols, i + 1)
        plt.imshow(x_test_images[idx], cmap="gray")
        plt.title(f"T:{true_label} P:{pred_label}\nConf:{confidence:.2f}")
        plt.axis("off")

    plt.suptitle(f"Misclassified Test Images - {model_name}", y=1.02, fontsize=14)
    plt.tight_layout()
    plt.show()
# ----------------------------
# Misclassified image examples (deeper error analysis)
# ----------------------------
show_misclassified_examples(sigmoid_model, "Sigmoid", x_test_flat, x_test, y_test, n=16)
show_misclassified_examples(tanh_model, "Tanh", x_test_flat, x_test, y_test, n=16)
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

def plot_confusion_matrices(model, model_name, x, y_true, labels=None):
    """
    Plots:
      1) Confusion matrix (raw counts) with values
      2) Confusion matrix (normalized) with values
    """
    if labels is None:
        labels = list(range(10))

    y_pred_probs = model.predict(x, verbose=0)
    y_pred = np.argmax(y_pred_probs, axis=1)

    # Counts matrix
    cm_counts = confusion_matrix(y_true, y_pred, labels=labels)
    disp_counts = ConfusionMatrixDisplay(confusion_matrix=cm_counts, display_labels=labels)

    fig1, ax1 = plt.subplots(figsize=(8, 7))
    disp_counts.plot(ax=ax1, cmap="Blues", values_format="d", colorbar=True)
    ax1.set_title(f"Confusion Matrix (Counts) - {model_name}")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # Normalized matrix (row-wise)
    cm_norm = confusion_matrix(y_true, y_pred, labels=labels, normalize="true")
    disp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=labels)

    fig2, ax2 = plt.subplots(figsize=(8, 7))
    disp_norm.plot(ax=ax2, cmap="Blues", values_format=".2f", colorbar=True)
    ax2.set_title(f"Confusion Matrix (Normalized) - {model_name}")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
plot_confusion_matrices(sigmoid_model, "Sigmoid", x_test_flat, y_test)


  # Confusion matrices with numerical values (counts + normalized)
plot_confusion_matrices(tanh_model, "Tanh", x_test_flat, y_test)

